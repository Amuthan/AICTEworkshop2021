{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Basic_physics_based_learning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0App6yYvW1O"
      },
      "source": [
        "**Introduction to physics based learning**  \n",
        "ATAL-AICTE Workshop on Multidisciplinary Design Optimization  \n",
        "Dec 9, 2021.\n",
        "\n",
        "\n",
        "**Amuthan A. Ramabathiran**  \n",
        "Dept. of Aerospace Engineering  \n",
        "IIT Bombay\n",
        "\n",
        "*E-mail:* amuthan \\_at\\_ aero.iitb.ac.in  \n",
        "*Webpage:* https://amuthan.github.io/webpage/\n",
        "\n",
        "**0. Introduction**\n",
        "\n",
        "The basic idea in physics based learning is to endow ML algorithms with known physical laws for the particular application under scrutiny. This notebook provides an elementary introduction to *physics based learning*.\n",
        "\n",
        "*Note:* This notebook does not have a lot of written explanations; please watch the workshop video for more details. (Link coming up soon!)\n",
        "\n",
        "**1. Automatic Differentiation with PyTorch**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccm8ztQ_vNE0"
      },
      "source": [
        "import numpy\n",
        "from matplotlib import pyplot\n",
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHgeZ16gwTUi"
      },
      "source": [
        "xt = torch.tensor(1.5, dtype=torch.float32, requires_grad=True)\n",
        "\n",
        "def f(x):\n",
        "  return x*x*torch.sin(x)\n",
        "\n",
        "def dfdx(x):\n",
        "  return 2*x*torch.sin(x) + x*x*torch.cos(x)\n",
        "\n",
        "yt = f(xt)\n",
        "dydt = dfdx(xt)\n",
        "print(f'y = {yt:.4f}, dydx = {dydt:.4f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MADwDg4w2Hg"
      },
      "source": [
        "yt.backward()\n",
        "print(f'dydt (AD) = {xt.grad:.4f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHAKDYw9xImq"
      },
      "source": [
        "def g(x):\n",
        "  return x*x\n",
        "\n",
        "def dgdx(x):\n",
        "  return 2*x\n",
        "\n",
        "zt = g(xt)\n",
        "dzdx = dgdx(xt)\n",
        "print(f'z = {zt:.4f}, dzdx = {dzdx:.4f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wkXQ9XYx0Ns"
      },
      "source": [
        "zt.backward()\n",
        "print(f'dzdt (AD; incorrect!) = {xt.grad:.4f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make sure you set the gradient to `None` explicitly before you perform a fresh computation!"
      ],
      "metadata": {
        "id": "GbDErX3XkMvS"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJodgV_CyCD2"
      },
      "source": [
        "xt.grad = None\n",
        "zt = g(xt)\n",
        "zt.backward()\n",
        "print(f'dzdx (AD; correct!) = {xt.grad:.4f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKuO2vk_1lV7"
      },
      "source": [
        "**2. Supervised vs physics-based learning**\n",
        "\n",
        "A very simple example illustrating the difference between supervised and physics-based learning, adapted from http://physicsbaseddeeplearning.org/intro-teaser.html.\n",
        "\n",
        "**2.1 Generate data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZtwZzfm1kL8",
        "collapsed": true
      },
      "source": [
        "def generate_circle_data(n_data):\n",
        "  xs = numpy.linspace(-1.0, 1.0, n_data)\n",
        "  ys = numpy.sqrt(1 - xs*xs)\n",
        "\n",
        "  for i in range(n_data):\n",
        "    if numpy.random.random() < 0.5:\n",
        "      ys[i] *= -1.0\n",
        "\n",
        "  return xs, ys\n",
        "\n",
        "n_data = 200\n",
        "xs, ys = generate_circle_data(n_data)\n",
        "\n",
        "pyplot.figure(figsize=(5,5))\n",
        "pyplot.plot(xs, ys, 'bo', markersize=5)\n",
        "pyplot.xlabel('x')\n",
        "pyplot.ylabel('y')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCznCLDqRH4J"
      },
      "source": [
        "PyTorch provides nice wrappers to handle data. We will use the `Dataset` and `DataLoader` classes from `torch.utils.data`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_m-ty-4Q1Q_"
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKUsdJSXRbJg"
      },
      "source": [
        "class SLdata(Dataset):\n",
        "  def __init__(self, xs, ys):\n",
        "    self.xs = torch.tensor(xs, dtype=torch.float32).unsqueeze(1)\n",
        "    self.ys = torch.tensor(ys, dtype=torch.float32).unsqueeze(1)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.ys)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    x = self.xs[idx]\n",
        "    y = self.ys[idx]\n",
        "    return x, y\n",
        "\n",
        "data_circ = SLdata(xs, ys)\n",
        "\n",
        "batch = 25\n",
        "dl_circ = DataLoader(data_circ, batch_size=batch, shuffle=True)\n",
        "\n",
        "for xb, yb in dl_circ:\n",
        "  print(xb)\n",
        "  print(yb)\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1AoFnSutSfoN"
      },
      "source": [
        "**2.2 Supervised learning**\n",
        "\n",
        "Set up neural network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdVBD0ONSVEB"
      },
      "source": [
        "class CircleNet(torch.nn.Module):\n",
        "  def __init__(self, n_hidden=10):\n",
        "    super(CircleNet, self).__init__()\n",
        "    self.n_hidden = n_hidden\n",
        "    self.layer1 = torch.nn.Linear(1, n_hidden)\n",
        "    self.layer2 = torch.nn.Linear(n_hidden, n_hidden)\n",
        "    self.layer3 = torch.nn.Linear(n_hidden, n_hidden)\n",
        "    self.layer4 = torch.nn.Linear(n_hidden, 1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.layer1(x)\n",
        "    x = torch.tanh(x)\n",
        "    x = self.layer2(x)\n",
        "    x = torch.tanh(x)\n",
        "    x = self.layer3(x)\n",
        "    x = torch.tanh(x)\n",
        "    x = self.layer4(x)\n",
        "    return x\n",
        "\n",
        "n_hidden = 20\n",
        "dnn_SL = CircleNet(n_hidden=n_hidden)\n",
        "\n",
        "dnn_SL(data_circ[0][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eie_udNrXVIP"
      },
      "source": [
        "Train DNN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVfTPv3EVwE0"
      },
      "source": [
        "def train_SL(model, loss_fn, optimizer, dl):\n",
        "  train_loss = 0.0\n",
        "  for xb, yb in dl:\n",
        "    optimizer.zero_grad()\n",
        "    ypred = model(xb)\n",
        "    loss = loss_fn(ypred, yb)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    train_loss += loss.item()\n",
        "  train_loss /= len(dl)\n",
        "  return train_loss\n",
        "\n",
        "epochs = 100\n",
        "lr = 1e-3\n",
        "optimizer = torch.optim.SGD(dnn_SL.parameters(), lr=lr)\n",
        "loss_fn = torch.nn.MSELoss()\n",
        "\n",
        "losses = []\n",
        "for epoch in range(epochs):\n",
        "  loss = train_SL(dnn_SL, loss_fn, optimizer, dl_circ)\n",
        "  losses.append(loss)\n",
        "  print(f'Epoch {epoch}/{epochs}: loss = {loss}')\n",
        "\n",
        "pyplot.loglog(losses, 'k-', linewidth=2)\n",
        "pyplot.xlabel('Epoch')\n",
        "pyplot.ylabel('Training loss')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyUwNP3QXaHD"
      },
      "source": [
        "Test DNN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLt_vEVpXIi5"
      },
      "source": [
        "n_test = 50\n",
        "xs_test = torch.linspace(-1.0, 1.0, n_test, dtype=torch.float32).unsqueeze(1)\n",
        "ys_SL = dnn_SL(xs_test)\n",
        "\n",
        "xp = xs_test.squeeze().detach().cpu().numpy()\n",
        "yp_SL = ys_SL.squeeze().detach().cpu().numpy()\n",
        "\n",
        "pyplot.figure(figsize=(5,5))\n",
        "pyplot.plot(xs, ys, 'ko', markersize=4, label='Data')\n",
        "pyplot.plot(xp, yp_SL, 'bo-', markersize=4, label='SL')\n",
        "pyplot.xlabel('x')\n",
        "pyplot.ylabel('y')\n",
        "pyplot.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Du7BD9maYakn"
      },
      "source": [
        "**2.3 Differentiable Physics**\n",
        "\n",
        "Generate data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hf0IG58-YSXA"
      },
      "source": [
        "class DPdata(Dataset):\n",
        "  def __init__(self, xs):\n",
        "    self.xs = torch.tensor(xs, dtype=torch.float32).unsqueeze(1)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.xs)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    x = self.xs[idx]\n",
        "    return x\n",
        "\n",
        "data_DP = DPdata(xs)\n",
        "\n",
        "batch = 25\n",
        "dl_DP = DataLoader(data_DP, batch_size=batch, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMfVepCQZGWo"
      },
      "source": [
        "Set up DNN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T61KGgRTY_MC"
      },
      "source": [
        "n_hidden = 20\n",
        "dnn_DP = CircleNet(n_hidden=n_hidden)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2NwmPb_ZbEN"
      },
      "source": [
        "Define loss function for DP."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9LJXanyZUke"
      },
      "source": [
        "def _physics(x, y):\n",
        "  return (x*x + y*y - 1.0)\n",
        "\n",
        "def loss_DP(model, xb):\n",
        "  yb = model(xb)\n",
        "  res = _physics(xb, yb)**2\n",
        "  return torch.mean(res)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLRivomCaRbf"
      },
      "source": [
        "Train DNN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FuFxknIfaP0H"
      },
      "source": [
        "def train_DP(model, loss_fn, optimizer, dl):\n",
        "  train_loss = 0.0\n",
        "  for xb in dl:\n",
        "    optimizer.zero_grad()\n",
        "    loss = loss_fn(model, xb)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    train_loss += loss.item()\n",
        "  train_loss /= len(dl)\n",
        "  return train_loss\n",
        "\n",
        "epochs = 1000\n",
        "lr = 5e-3\n",
        "optimizer = torch.optim.SGD(dnn_DP.parameters(), lr=lr)\n",
        "\n",
        "losses = []\n",
        "for epoch in range(epochs):\n",
        "  loss = train_DP(dnn_DP, loss_DP, optimizer, dl_DP)\n",
        "  losses.append(loss)\n",
        "  if epoch%100 == 0:\n",
        "    print(f'Epoch {epoch}/{epochs}: loss = {loss}')\n",
        "\n",
        "pyplot.loglog(losses, 'k-', linewidth=2)\n",
        "pyplot.xlabel('Epoch')\n",
        "pyplot.ylabel('Training loss')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6fj3ARIb9hP"
      },
      "source": [
        "Test DNN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbtbU6jubR0o"
      },
      "source": [
        "ys_DP = dnn_DP(xs_test)\n",
        "yp_DP = ys_DP.squeeze().detach().cpu().numpy()\n",
        "\n",
        "pyplot.figure(figsize=(5,5))\n",
        "pyplot.plot(xs, ys, 'ko', markersize=4, label='Data')\n",
        "pyplot.plot(xp, yp_SL, 'bo-', markersize=4, label='SL')\n",
        "pyplot.plot(xp, yp_DP, 'ro-', markersize=4, label='DP')\n",
        "pyplot.xlabel('x')\n",
        "pyplot.ylabel('y')\n",
        "pyplot.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eH1O2dKycyqu"
      },
      "source": [
        "**3. Solving ODEs with DNN**\n",
        "\n",
        "Consider the simple ODE\n",
        "\n",
        "$$\n",
        "\\frac{dx(t)}{dt} = 2\\pi \\cos (2\\pi t), \\quad x(0) = 1.\n",
        "$$\n",
        "\n",
        "The exact solution to this ODE is\n",
        "\n",
        "$$\n",
        "x(t) = 1 + \\sin (2\\pi t).\n",
        "$$\n",
        "\n",
        "This is now solved using both finite difference and DNN approximations.\n",
        "\n",
        "**3.1 Forward Euler method**\n",
        "\n",
        "The forward Euler finite difference scheme for this ODE takes the following iterative form: \n",
        "\n",
        "$$\n",
        "x_{n+1} = x_n + 2\\pi \\Delta t \\cos (2 \\pi t_n), \\quad n \\ge 0. \n",
        "$$\n",
        "\n",
        "We will solve this over the intervar $[0,1]$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8to94SZcNYz"
      },
      "source": [
        "t0 = 0.0\n",
        "tf = 1.0\n",
        "dt = 0.01\n",
        "nt = int((tf - t0)/dt)\n",
        "\n",
        "x0 = 1.0\n",
        "pi = numpy.pi\n",
        "\n",
        "def f_ODE(t):\n",
        "  return 2*pi*numpy.cos(2*pi*t)\n",
        "\n",
        "def x_exact(t):\n",
        "  return 1 + numpy.sin(2*pi*t)\n",
        "\n",
        "def forward_Euler(x0, t0, dt, nt):\n",
        "  xs = [x0]\n",
        "  for i in range(nt):\n",
        "    t = t0 + i*dt\n",
        "    xn = xs[-1]\n",
        "    x = xn + dt*f_ODE(t)\n",
        "    xs.append(x)\n",
        "  return xs\n",
        "\n",
        "xs = forward_Euler(x0, t0, dt, nt)\n",
        "ts = numpy.linspace(t0, tf, (nt + 1))\n",
        "xs_exact = x_exact(ts)\n",
        "\n",
        "pyplot.plot(ts, xs_exact, 'k-', linewidth=2, label='Exact')\n",
        "pyplot.plot(ts, xs, 'bo', markersize=4, label='FD')\n",
        "pyplot.xlabel('t')\n",
        "pyplot.ylabel('x')\n",
        "pyplot.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.2 DNN**\n",
        "\n",
        "We will approximate the solution $x(t)$ by a DNN $\\hat{x}(t; \\theta)$, and enforce the boundary condition $\\hat{x}(0; \\theta) = 1$ using the penalty method.\n",
        "\n",
        "The approach is similar to what we had earlier, except that the derivative $d\\hat{x}(t; \\theta)/dt$ is computed using finite differences."
      ],
      "metadata": {
        "id": "ztKpOhc1nbY-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ODEdata(Dataset):\n",
        "  def __init__(self, ts):\n",
        "    self.ts = torch.tensor(ts, dtype=torch.float32).unsqueeze(1)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.ts)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    t = self.ts[idx]\n",
        "    return t\n",
        "\n",
        "class ODENet(torch.nn.Module):\n",
        "  def __init__(self, n_hidden=10):\n",
        "    super(ODENet, self).__init__()\n",
        "    self.n_hidden = n_hidden\n",
        "    self.layer1 = torch.nn.Linear(1, n_hidden)\n",
        "    self.layer2 = torch.nn.Linear(n_hidden, n_hidden)\n",
        "    self.layer3 = torch.nn.Linear(n_hidden, 1)\n",
        "\n",
        "  def forward(self, t):\n",
        "    x = self.layer1(t)\n",
        "    x = torch.tanh(x)\n",
        "    x = self.layer2(x)\n",
        "    x = torch.tanh(x)\n",
        "    x = self.layer3(x)\n",
        "    return x\n",
        "\n",
        "def _ode(t, x, xt):\n",
        "  return xt - 2*pi*torch.cos(2*pi*t)\n",
        "\n",
        "def loss_ODE(model, tb, h, t0, x0, wt):\n",
        "  xb = model(tb)\n",
        "  xbt = (model(tb + h) - xb)/h \n",
        "  ode = _ode(tb, xb, xbt)\n",
        "  res_int = torch.mean(ode**2)\n",
        "  res_bdy = (model(torch.tensor([t0], dtype=torch.float32)) - x0)**2\n",
        "  res = res_int + wt*res_bdy\n",
        "  return res\n",
        "\n",
        "def train_ODE(model, optimizer, dl, \n",
        "              h=1e-4, t0=0.0, x0=0.0, wt=1.0):\n",
        "  train_loss = 0.0\n",
        "  for tb in dl:\n",
        "    optimizer.zero_grad()\n",
        "    loss = loss_ODE(model, tb, h, t0, x0, wt)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    train_loss += loss.item()\n",
        "  train_loss /= len(dl)\n",
        "  return train_loss\n",
        "\n",
        "data_ode = ODEdata(ts)\n",
        "batch = 20\n",
        "dl_ode = DataLoader(data_ode, batch_size=batch, shuffle=True)\n",
        "\n",
        "n_hidden = 20\n",
        "dnn_ode = ODENet(n_hidden=n_hidden)\n",
        "\n",
        "epochs = 1000\n",
        "lr = 1e-3\n",
        "optimizer = torch.optim.SGD(dnn_ode.parameters(), lr=lr)\n",
        "\n",
        "losses = []\n",
        "for epoch in range(epochs):\n",
        "  loss = train_ODE(dnn_ode, optimizer, dl_ode, x0=1.0, wt=10.0)\n",
        "  losses.append(loss)\n",
        "  if epoch%100 == 0:\n",
        "    print(f'Epoch {epoch}/{epochs}: loss = {loss}')\n",
        "\n",
        "pyplot.loglog(losses, 'k-', linewidth=2)\n",
        "pyplot.xlabel('Epoch')\n",
        "pyplot.ylabel('Training loss')"
      ],
      "metadata": {
        "id": "2htwmcRynXXU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test DNN solution."
      ],
      "metadata": {
        "id": "qrBQEwMhs3jV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_test = 20\n",
        "ts_test = numpy.linspace(t0, tf, n_test)\n",
        "tp = torch.tensor(ts_test, dtype=torch.float32).unsqueeze(1)\n",
        "xs_dnn = dnn_ode(tp)\n",
        "xp = xs_dnn.squeeze().detach().cpu().numpy()\n",
        "\n",
        "pyplot.plot(ts, xs_exact, 'k-', linewidth=2, label='Exact')\n",
        "pyplot.plot(ts, xs, 'bo', markersize=4, label='FD')\n",
        "pyplot.plot(tp, xp, 'rs-', markersize=4, label='DNN')\n",
        "pyplot.xlabel('t')\n",
        "pyplot.ylabel('x')\n",
        "pyplot.legend()"
      ],
      "metadata": {
        "id": "K_pVst7esX4W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Inverse problem: simulation of cricket ball trajectory**\n",
        "\n",
        "**4.1 Trajectory simulation**"
      ],
      "metadata": {
        "id": "hCEZNnKZtZ0G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "g = 9.81 # m/s^2\n",
        "m = 0.16 # kg\n",
        "r = 0.036 # m\n",
        "A = pi*r*r # m^2\n",
        "rho = 1.225 # kg/m^3\n",
        "C = 0.5*rho*A/m # 1/m\n",
        "Cd = 0.5 # nondim\n",
        "\n",
        "L = 20.12 - 1.22 # m; pitch length - crease length\n",
        "H = 2.5 # m; maximum height of release\n",
        "S = 0.71 # m; stumps height\n",
        "\n",
        "deg2rad = pi/180.0\n",
        "kmph2mps = 0.277778\n",
        "\n",
        "def get_position(release):\n",
        "  xs = torch.zeros(2, dtype=torch.float32)\n",
        "  xs[0] = H*torch.sin(release)\n",
        "  xs[1] = H*torch.cos(release)\n",
        "  return xs\n",
        "\n",
        "def get_velocity(release, speed):\n",
        "  vs = torch.zeros(2, dtype=torch.float32)\n",
        "  vs[0] = speed*torch.cos(release)\n",
        "  vs[1] = -speed*torch.sin(release)\n",
        "  return vs\n",
        "\n",
        "def f_traj(u, v, windspeed):\n",
        "  fs = torch.zeros(2)\n",
        "  v_norm = torch.sqrt((u - windspeed)**2 + v**2)\n",
        "  fs[0] = -v_norm*C*Cd*(u - windspeed)\n",
        "  fs[1] = -v_norm*C*Cd*v - g\n",
        "  return fs \n",
        "\n",
        "# This is a symplectic Euler scheme!\n",
        "def step_Euler(xs, vs, windspeed, dt):\n",
        "  vs = vs + dt*f_traj(*vs, windspeed)\n",
        "  xs = xs + dt*vs\n",
        "  return xs, vs\n",
        "\n",
        "def wicket(x, y):\n",
        "  if abs(x - L) < 0.075 and y >= 0.0 and y <= S:\n",
        "    return True\n",
        "  else:\n",
        "    return False\n",
        "\n",
        "def bowl(xs, vs, windspeed, bounce, dt, \n",
        "         max_itr=1000, history=False):\n",
        "  itr = 0\n",
        "  traj = []\n",
        "  if history:\n",
        "    traj.append(xs)\n",
        "  first_bounce = True\n",
        "  \n",
        "  while xs[0] <= L and itr <= max_itr:\n",
        "    itr += 1\n",
        "    xs, vs = step_Euler(xs, vs, windspeed, dt)\n",
        "    if xs[1] <= 0.0 and first_bounce:\n",
        "      vs[1] = -bounce*vs[1]\n",
        "      first_bounce = False\n",
        "    if history:\n",
        "      traj.append(xs)\n",
        "\n",
        "  if history:\n",
        "    return traj\n",
        "  else:\n",
        "    return xs\n",
        "\n",
        "def plot_trajectory(traj):\n",
        "  xs = []\n",
        "  ys = []\n",
        "  for xy in traj:\n",
        "    xs.append(xy[0].item())\n",
        "    ys.append(xy[1].item())\n",
        "\n",
        "  pyplot.plot([0,L],[0,0], 'k-', linewidth=8)\n",
        "  pyplot.plot([0,L],[S,S], 'k--', linewidth=2)\n",
        "  pyplot.plot([L,L], [0,S], 'k-', linewidth=4)\n",
        "  pyplot.plot(xs, ys, 'b-', linewidth=3)\n",
        "  pyplot.plot([L], [ys[-1]], 'r*', markersize=20)\n",
        "  pyplot.xlabel('Pitch')\n",
        "  pyplot.ylabel('Height')\n",
        "  pyplot.xlim((-0.3, L + 0.3))\n",
        "  pyplot.ylim((-0.1, H + 0.1))\n",
        "\n",
        "# Example of a trajectory\n",
        "speed = 140*kmph2mps\n",
        "release = 6*deg2rad\n",
        "windspeed = -4.0*kmph2mps\n",
        "bounce = 0.7\n",
        "\n",
        "xs = get_position(torch.tensor(release, dtype=torch.float32))\n",
        "vs = get_velocity(torch.tensor(release, dtype=torch.float32),\n",
        "                  torch.tensor(speed, dtype=torch.float32))\n",
        "\n",
        "dt = 0.005 # s\n",
        "traj = bowl(xs, vs, windspeed, bounce, dt, history=True)\n",
        "\n",
        "pyplot.figure(figsize=(10,5))\n",
        "plot_trajectory(traj)\n",
        "\n",
        "speed = 120*kmph2mps\n",
        "release = 10*deg2rad\n",
        "windspeed = -4.0*kmph2mps\n",
        "bounce = 0.7\n",
        "\n",
        "xs = get_position(torch.tensor(release, dtype=torch.float32))\n",
        "vs = get_velocity(torch.tensor(release, dtype=torch.float32),\n",
        "                  torch.tensor(speed, dtype=torch.float32))\n",
        "\n",
        "dt = 0.005 # s\n",
        "traj = bowl(xs, vs, windspeed, bounce, dt, history=True)\n",
        "\n",
        "plot_trajectory(traj)"
      ],
      "metadata": {
        "id": "Rykw_1yntU6N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.2 Inverse problem - learning to bowl!**"
      ],
      "metadata": {
        "id": "vmQZwbbx_LD5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(x, a=2.0):\n",
        "  return 1.0/(1.0 + torch.exp(-a*x))\n",
        "\n",
        "# Input: windspeed, pitch bounce\n",
        "# Output: release angle, speed\n",
        "class Bowl(torch.nn.Module):\n",
        "  def __init__(self, n_hidden=10, scale=1.0):\n",
        "    super(Bowl, self).__init__()\n",
        "    self.n_hidden = n_hidden\n",
        "    self.scale = scale\n",
        "    self.layer1 = torch.nn.Linear(2, n_hidden)\n",
        "    self.layer2 = torch.nn.Linear(n_hidden, n_hidden)\n",
        "    self.layer3 = torch.nn.Linear(n_hidden, 2)\n",
        "    self.act = torch.nn.ReLU()\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.layer1(x)\n",
        "    x = self.act(x)\n",
        "    x = self.layer2(x)\n",
        "    x = self.act(x)\n",
        "    x = self.layer3(x)\n",
        "    x = sigmoid(x, self.scale) # To scale output to [0,1]\n",
        "    return x\n",
        "\n",
        "xs_wicket = torch.tensor(\n",
        "    [L, 0.75*S], dtype=torch.float32\n",
        ")\n",
        "speed_lo = 100*kmph2mps\n",
        "speed_hi = 160*kmph2mps\n",
        "release_lo = 0.0*deg2rad\n",
        "release_hi = 10.0*deg2rad\n",
        "\n",
        "def loss_bowl(model, windspeed, bounce, dt):\n",
        "  wb = torch.tensor(\n",
        "      [windspeed, bounce], dtype=torch.float32, requires_grad=True\n",
        "  )\n",
        "  rs = model(wb)\n",
        "  release = release_lo + (release_hi - release_lo)*rs[0]\n",
        "  speed = speed_lo + (speed_hi - speed_lo)*rs[1]\n",
        "  xs = get_position(release)\n",
        "  vs = get_velocity(release, speed)\n",
        "  xs = bowl(xs, vs, windspeed, bounce, dt)\n",
        "  loss = 0.5*torch.norm(xs - xs_wicket)**2\n",
        "  return loss \n",
        "\n",
        "def train_bowl(model, optimizer, windspeeds, bounces, dt):\n",
        "  train_loss = 0.0\n",
        "  for w, b in zip(windspeeds, bounces):\n",
        "    optimizer.zero_grad()\n",
        "    loss = loss_bowl(model, w, b, dt)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    train_loss += loss.item()\n",
        "  train_loss /= len(windspeeds)\n",
        "  return train_loss"
      ],
      "metadata": {
        "id": "wRPyphP5-vuO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training DNN."
      ],
      "metadata": {
        "id": "7XITCHOuBhcS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_bowl = 30\n",
        "max_windspeed = 2.0*kmph2mps\n",
        "bounce_lo = 0.9\n",
        "bounce_spread = 0.1\n",
        "windspeeds = (2*numpy.random.random(n_bowl) - 1)*max_windspeed \n",
        "bounces = bounce_lo + numpy.random.random(n_bowl)*bounce_spread\n",
        "\n",
        "n_hidden = 10\n",
        "scale = 0.5\n",
        "dnn_bowl = Bowl(n_hidden=n_hidden, scale=scale)\n",
        "\n",
        "epochs = 50\n",
        "lr = 1e-6\n",
        "optimizer = torch.optim.Adam(dnn_bowl.parameters(), lr=lr) #, \n",
        "                            # momentum=0.9)\n",
        "\n",
        "dt = 0.002 # s\n",
        "\n",
        "losses = []\n",
        "for epoch in range(epochs):\n",
        "  loss = train_bowl(dnn_bowl, optimizer, windspeeds, bounces, dt)\n",
        "  losses.append(loss)\n",
        "  print(f'Epoch {epoch}/{epochs}: loss = {loss}')\n",
        "\n",
        "pyplot.loglog(losses, 'k-', linewidth=2)\n",
        "pyplot.xlabel('Epoch')\n",
        "pyplot.ylabel('Training loss')"
      ],
      "metadata": {
        "id": "95urV8hPBfAV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training accuracy and performance of trained DNN on training conditions."
      ],
      "metadata": {
        "id": "tjJOh4y9laCj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = 0.0\n",
        "\n",
        "pyplot.figure(figsize=(10,5))\n",
        "for i in range(n_bowl):\n",
        "  rs = dnn_bowl(torch.tensor(\n",
        "      [windspeeds[i], bounces[i]], dtype=torch.float32\n",
        "  ))\n",
        "  release = release_lo + (release_hi - release_lo)*rs[0]\n",
        "  speed = speed_lo + (speed_hi - speed_lo)*rs[1]\n",
        "  print(f'Train {i}/{n_bowl}: Release angle = {release/deg2rad}, ' \\\n",
        "        f'Speed = {speed/kmph2mps} kmph')\n",
        "  xs = get_position(release)\n",
        "  vs = get_velocity(release, speed)\n",
        "\n",
        "  traj = bowl(xs, vs, windspeeds[i], bounces[i], dt, history=True)\n",
        "  plot_trajectory(traj)\n",
        "\n",
        "  xs = traj[-1]\n",
        "  if wicket(xs[0], xs[1]):\n",
        "    print(f'Train {i}/{n_bowl}: Wicket!')\n",
        "    accuracy += 1\n",
        "  else:\n",
        "    print(f'Train {i}/{n_bowl}: Miss!')\n",
        "\n",
        "accuracy /= n_bowl\n",
        "print(f'Bowling accuracy (train) = {accuracy}')"
      ],
      "metadata": {
        "id": "K4FJkeFDvzIK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test DNN."
      ],
      "metadata": {
        "id": "OhWqHdvQC55F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_test = 30\n",
        "max_windspeed = 10.0*kmph2mps\n",
        "bounce_lo = 0.7\n",
        "bounce_spread = 0.3\n",
        "ws_test = (2*numpy.random.random(n_test) - 1)*max_windspeed\n",
        "b_test = bounce_lo + numpy.random.random(n_test)*bounce_spread\n",
        "accuracy = 0.0\n",
        "\n",
        "pyplot.figure(figsize=(10,5))\n",
        "for i in range(n_test):\n",
        "  rs = dnn_bowl(torch.tensor(\n",
        "      [ws_test[i], b_test[i]], dtype=torch.float32\n",
        "  ))\n",
        "  release = release_lo + (release_hi - release_lo)*rs[0]\n",
        "  speed = speed_lo + (speed_hi - speed_lo)*rs[1]\n",
        "  print(f'Test {i}/{n_test}: Release angle = {release/deg2rad}, ' \\\n",
        "        f'Speed = {speed/kmph2mps} kmph')\n",
        "  xs = get_position(release)\n",
        "  vs = get_velocity(release, speed)\n",
        "\n",
        "  traj = bowl(xs, vs, ws_test[i], b_test[i], dt, history=True)\n",
        "  plot_trajectory(traj)\n",
        "\n",
        "  xs = traj[-1]\n",
        "  if wicket(xs[0], xs[1]):\n",
        "    print(f'Test {i}/{n_test}: Wicket!')\n",
        "    accuracy += 1\n",
        "  else:\n",
        "    print(f'Test {i}/{n_test}: Miss!')\n",
        "\n",
        "accuracy /= n_test\n",
        "print(f'Bowling accuracy = {accuracy}')"
      ],
      "metadata": {
        "id": "RquXVRicCiEi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}